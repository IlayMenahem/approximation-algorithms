% set document class and formatting
\documentclass[12pt]{article}

% import packages
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry} 
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{fancyhdr}


% set title and authors
\title{Approximation Algorithms - Homework 2}
\author{Ilay Menahem, and Aaron Ross}

% Page Setup (matching guidelines: 2.5cm margins)
\geometry{margin=2.5cm}


% Theorem Environments
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}

% Custom Commands
\newcommand{\eps}{\epsilon}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}

\begin{document}

\maketitle

\section*{Problem 1: Weighted Max-Cut Local Search}

\subsection*{(a) Polynomial Convergence}

\subsubsection*{Overview}
We analyze the $LS_{Max-Cut}$ algorithm where a local move is made only if the weight of the cut increases by a factor of at least $(1 + \frac{\eps}{n})$. We show that the number of iterations is polynomial in the input size and $1/\eps$.

\subsubsection*{Proof of Validity}
Let $W(S)$ denote the weight of the cut $(S, V \setminus S)$. Let $S_k$ be the cut after $k$ iterations, and $S_0$ be the initial cut. The algorithm updates $S_k$ to $S_{k+1}$ only if:
\[
W(S_{k+1}) \ge \left(1 + \frac{\eps}{n}\right)W(S_k)
\]
Therefore, after $k$ iterations:
\[
W(S_k) \ge \left(1 + \frac{\eps}{n}\right)^k W(S_0)
\]
The maximum possible weight of any cut is bounded by the total weight of all edges, denoted $W_{total}$. Thus:
\[
\left(1 + \frac{\eps}{n}\right)^k W(S_0) \le W(S_k) \le W_{total}
\]

\subsubsection*{Complexity Analysis}
Taking the natural logarithm of the inequality:
\[
k \ln\left(1 + \frac{\eps}{n}\right) + \ln(W(S_0)) \le \ln(W_{total})
\]
Using the inequality $\ln(1+x) \approx x$ for small $x$ (specifically $\ln(1+x) \ge \frac{x}{1+x}$ or simply bounding by linear growth for complexity):
\[
k \cdot \frac{\eps}{2n} \le k \ln\left(1 + \frac{\eps}{n}\right) \le \ln(W_{total}) - \ln(W(S_0)) = \ln\left(\frac{W_{total}}{W(S_0)}\right)
\]
\[
k \le \frac{2n}{\eps} \ln\left(\frac{W_{total}}{W(S_0)}\right)
\]
Since $\ln(W_{total})$ is polynomial in the input size (number of bits to represent weights), $k$ is polynomial.

\subsection*{(b) Improved Bound with Specific Initialization}

\subsubsection*{Algorithm Modification}
Initialize $S_0 = \{v^*\}$, where $v^* = \arg\max_{v \in V} w(\{v\}, V \setminus \{v\})$.

\subsubsection*{Complexity Analysis}
1.  \textbf{Lower Bound of Initialization:}
    Let $w(v)$ be the sum of weights of edges incident to $v$. We know $\sum_{v \in V} w(v) = 2 W_{total}$. By the Pigeonhole Principle, there exists a vertex $v^*$ such that:
    \[ w(v^*) \ge \frac{2 W_{total}}{n} \]
    The initial cut weight is $W(S_0) = w(v^*)$, so $W(S_0) \ge \frac{2 W_{total}}{n}$.

2.  \textbf{Upper Bound on Iterations:}
    The optimal cut $W_{OPT}$ is bounded by $W_{total}$. Substituting this into the iteration bound from part (a):
    \[
    k \le O\left(\frac{n}{\eps}\right) \ln\left(\frac{W_{total}}{2 W_{total} / n}\right) = O\left(\frac{n}{\eps}\right) \ln\left(\frac{n}{2}\right) = O\left(\frac{n \log n}{\eps}\right)
    \]
    Thus, the number of iterations is $O(\frac{n \log n}{\eps})$.

\newpage

\section*{Problem 2: Hitting Set}

\subsection*{Algorithm: Recursive Local Ratio}
The algorithm takes a universe $U$, a collection of sets $\mathcal{C}$, and weights $w$.

\begin{algorithm}[H]
\caption{Local Ratio for Hitting Set}
\begin{algorithmic}[1]
\Function{HittingSet}{$U, \mathcal{C}, w$}
    \State Remove all $x \in U$ with $w(x) \le 0$ (add to solution $H$).
    \If{$\mathcal{C} = \emptyset$} \Return $\emptyset$ \EndIf
    \State Pick any set $S_i \in \mathcal{C}$.
    \State Let $\eps = \min_{x \in S_i} w(x)$.
    \State Define $w_1(x) = \begin{cases} \eps & \text{if } x \in S_i \\ 0 & \text{otherwise} \end{cases}$
    \State Define $w_2(x) = w(x) - w_1(x)$.
    \State $H' \gets \Call{HittingSet}{U, \mathcal{C}, w_2}$
    \If{$H' \cap S_i = \emptyset$}
        \State Find $x \in S_i$ such that $w_2(x) = 0$ (must exist as we subtracted min).
        \State $H \gets H' \cup \{x\}$
    \Else
        \State $H \gets H'$
    \EndIf
    \State \Return $H$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection*{Approximation Analysis}
We prove that $w(H) \le S_{max} \cdot w(H_{OPT})$, where $S_{max} = \max_i |S_i|$.
According to the Local Ratio Theorem, it suffices to show the approximation holds for $w_1$ and $w_2$.

\begin{proof}
    \textbf{Inductive Step:} Assume the algorithm is an $S_{max}$-approximation for $w_2$.
    
    \textbf{For $w_1$:}
    \begin{itemize}
        \item The optimal solution $H_{OPT}$ must pick at least one element from $S_i$ to cover it. Thus, $w_1(H_{OPT}) \ge \eps$.
        \item Our solution $H$ adds at most one element specifically for $S_i$ (if not already covered). However, even if we consider the set of all chosen elements, strictly speaking, $w_1(H) = \eps \cdot |H \cap S_i|$.
        \item While $|H \cap S_i|$ could be large in theory, the standard Local Ratio analysis for covering problems relies on comparing the cost paid to the optimum.
        \item A simpler view: The total weight removed from the system is $\eps$ per element in $S_i$. The optimal solution pays at least $\eps$.
        \item The algorithm ensures minimality with respect to the decomposition.
        \item Specifically for Hitting Set (dual of Set Cover with frequency $f=S_{max}$), any minimal solution is an $S_{max}$-approximation with respect to $w_1$.
        \[ w_1(H) \le |S_i| \cdot \eps \le S_{max} \cdot \eps \le S_{max} \cdot w_1(H_{OPT}) \]
    \end{itemize}
    
    \textbf{Total:}
    \[ w(H) = w_1(H) + w_2(H) \le S_{max} w_1(H_{OPT}) + S_{max} w_2(H_{OPT}) = S_{max} \cdot w(H_{OPT}) \]
\end{proof}

\newpage

\section*{Problem 3: Multiple Choice Maximum Coverage}

\subsection*{Overview}
We prove the local search algorithm is a $\frac{1}{2}$-approximation. Let $S = (j_1, \dots, j_k)$ be the local optimum solution and $O = (o_1, \dots, o_k)$ be the global optimal solution.

\subsection*{Definitions (from Hint)}
Let $U_S = \bigcup_{i=1}^k S_{i,j_i}$ be the set of elements covered by our solution.
For each $1 \le i \le k$, define:
\begin{align*}
    A_i &= S_{i,j_i} \setminus \bigcup_{r \ne i} S_{r,j_r} \quad \text{(Unique contribution of set } i \text{ in } S\text{)} \\
    B_i &= S_{i,o_i} \setminus \bigcup_{r \ne i} S_{r,j_r} \quad \text{(Gain of switching set } i \text{ to optimal choice given others fixed)}
\end{align*}

\subsection*{Proof}
\begin{enumerate}
    \item \textbf{Local Optimality:}
    Since the algorithm terminates, switching any single index $j_i$ to $o_i$ does not improve the value.
    The loss of removing $S_{i,j_i}$ is exactly $|A_i|$. The gain of adding $S_{i,o_i}$ (relative to the other current sets) is exactly $|B_i|$.
    \[ |B_i| - |A_i| \le 0 \implies |B_i| \le |A_i| \]

    \item \textbf{Summation:}
    Summing over all $i=1 \dots k$:
    \[ \sum_{i=1}^k |B_i| \le \sum_{i=1}^k |A_i| \]
    Note that $\{A_i\}$ are disjoint subsets of $U_S$, and their union is exactly $U_S$ (since every element in the union must be unique to some set or shared; if shared, it is not lost when removing one, but $A_i$ captures the "ownership"). Actually, more precisely: $\sum |A_i| \le |U_S| = V(S)$. In fact, $\sum |A_i| = V(S)$ is not strictly true if there is overlap, but $\sum |A_i| \le V(S)$ holds.
    Wait, let us refine the definition of $A_i$. The hint defines $A_i$ as the contribution of set $i$ \textit{given the others}.
    The sets $A_i$ are disjoint. $\bigcup A_i \subseteq U_S$. Thus $\sum |A_i| \le V(S)$.

    \item \textbf{Bounding the Optimum:}
    Let $U_{OPT} = \bigcup S_{i,o_i}$. Consider any element $x \in U_{OPT} \setminus U_S$.
    Since $x$ is not in $U_S$, it is not in any $S_{r,j_r}$ for any $r$.
    Since $x \in U_{OPT}$, there exists some $i$ such that $x \in S_{i,o_i}$.
    Therefore, $x \in S_{i,o_i} \setminus \bigcup_{r \ne i} S_{r,j_r}$, which means $x \in B_i$.
    This implies:
    \[ U_{OPT} \setminus U_S \subseteq \bigcup_{i=1}^k B_i \]
    \[ |U_{OPT}| - |U_S| \le |U_{OPT} \setminus U_S| \le \sum_{i=1}^k |B_i| \]

    \item \textbf{Conclusion:}
    Combining the inequalities:
    \[ |U_{OPT}| - V(S) \le \sum_{i=1}^k |B_i| \le \sum_{i=1}^k |A_i| \le V(S) \]
    \[ |U_{OPT}| \le 2 V(S) \implies V(S) \ge \frac{1}{2} V(OPT) \]
\end{enumerate}

\newpage

\section*{Problem 4: Generalized Steiner Forest (GSF)}

\subsection*{(a) Minimal GSF is a 2-approximation for $w'$}

\textbf{Claim:} Let $w'(u,v) = |\{u,v\} \cap T|$. Any minimal GSF $F$ satisfies $w'(F) \le 2 w'(F_{OPT})$.

\begin{proof}
    \textbf{Lower Bound ($OPT$):}
    Consider the optimal solution $F^*$. Since $|T_i| \ge 2$, every terminal $v \in T$ must be connected to at least one other terminal. Thus, every $v \in T$ has degree at least 1 in $F^*$.
    \[ w'(F^*) = \sum_{(u,v) \in F^*} |\{u,v\} \cap T| = \sum_{v \in T} \deg_{F^*}(v) \ge \sum_{v \in T} 1 = |T| \]
    
    \textbf{Upper Bound (Minimal Forest $F$):}
    Since $F$ is a minimal GSF, every leaf in every connected component of $F$ must be a terminal in $T$. (If a leaf were not a terminal, the incident edge could be removed).
    For any tree in $F$, the sum of degrees of the vertices in $T$ is strictly less than $2 \times (\text{number of vertices in } T \text{ in that tree})$. Summing over all components:
    \[ w'(F) = \sum_{v \in T} \deg_F(v) \le 2|T| - 2 \times (\#\text{components}) < 2|T| \]
    
    \textbf{Ratio:}
    \[ w'(F) < 2|T| \le 2 w'(F^*) \]
\end{proof}

\subsection*{(b) Local Ratio Algorithm}

\begin{enumerate}
    \item \textbf{Base Case:} If all connectivity requirements are satisfied by 0-weight edges, return the set of those edges (pruned to be minimal).
    \item \textbf{Weight Definition:} Define $w'(e) = |e \cap T|$.
    \item \textbf{Compute $\eps$:} Let $\eps = \min \{ \frac{w(e)}{w'(e)} \mid w'(e) > 0, e \in E \}$.
    \item \textbf{Decomposition:}
    \[ w_1(e) = \eps \cdot w'(e) \]
    \[ w_2(e) = w(e) - w_1(e) \]
    \item \textbf{Recursion:} Solve recursively for $w_2$ to obtain forest $F'$.
    \item \textbf{Pruning (Crucial):} $F'$ is a valid GSF. Remove edges from $F'$ one by one as long as the connectivity requirements $T_i$ remain satisfied. Let the result be $F$.
    \item \textbf{Return} $F$.
\end{enumerate}

\textbf{Approximation:} By the Local Ratio Theorem, since $F$ is a minimal GSF, it is a 2-approximation for $w_1$ (by part a). By induction, it is a 2-approximation for $w_2$. Thus, it is a 2-approximation for $w$.

\newpage

\section*{Problem 5: Knapsack with Partition Constraints}

\subsection*{Overview}
We first define a Dynamic Programming (DP) algorithm that runs in pseudo-polynomial time, then apply the scaling technique to obtain an FPTAS.

\subsection*{Dynamic Programming}
Let the items be ordered such that items in $S_1$ appear first, then $S_2$, etc.
We compress the state to handle one group at a time.
\begin{itemize}
    \item $D_{prev}[v]$: Min weight to achieve value $v$ using previous groups.
    \item $D_{curr}[c][v]$: Min weight to achieve value $v$ using previous groups AND exactly $c$ items from the current group.
\end{itemize}

\textbf{Transitions:}
For each group $S_j$ with limit $k(j)$:
\begin{enumerate}
    \item Initialize $D_{curr}[0][v] = D_{prev}[v]$.
    \item For each item $i \in S_j$ (weight $w_i$, value $v_i$):
    \[ D_{curr}[c][v] = \min \left( D_{curr}[c][v], \quad D_{curr}[c-1][v-v_i] + w_i \right) \]
    (Iterate $c$ from $k(j)$ down to 1).
    \item After processing all items in $S_j$, update $D_{prev}$:
    \[ D_{prev}[v] = \min_{0 \le c \le k(j)} D_{curr}[c][v] \]
\end{enumerate}
The complexity is $O(n \cdot n \cdot V_{total}) = O(n^2 V_{total})$ since the inner $c$ loop runs at most $n$ times.

\subsection*{FPTAS Construction}
To achieve a $(1-\eps)$-approximation:

\begin{enumerate}
    \item Let $V_{max} = \max_i v_i$.
    \item Define scaling factor $K = \frac{\eps V_{max}}{n}$.
    \item Define scaled values $v'_i = \lfloor \frac{v_i}{K} \rfloor$.
    \item Run the DP algorithm using weights $w_i$ and values $v'_i$.
    \item Output the set of items corresponding to the optimal DP state satisfying weight $\le B$.
\end{enumerate}

\subsection*{Complexity and Bound}
The maximum possible scaled value is bounded by:
\[ V'_{total} \le \sum v'_i \le n \cdot \frac{V_{max}}{K} = n \cdot \frac{n}{\eps} = \frac{n^2}{\eps} \]
The DP running time becomes:
\[ O\left(n^2 \cdot \frac{n^2}{\eps}\right) = O\left(\frac{n^4}{\eps}\right) \]
This is polynomial in $n$ and $1/\eps$.

\textbf{Approximation Proof:}
For the optimal set $P^*$, the difference between the true value and the scaled value is:
\[ \sum_{i \in P^*} v_i - K \sum_{i \in P^*} v'_i < \sum_{i \in P^*} K = |P^*| K \le n K = \eps V_{max} \le \eps OPT \]
Thus, the solution returned is at least $(1-\eps)OPT$.

\end{document}